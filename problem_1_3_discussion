Problem 1.3 Discusssion 

Running the python script for this problem (python problem_1_3.py) in this repository a number of times we get the following results:

Run 1: 

Linear Regression
	MSE without CV: 3449.19
	MSE with CV: 3000.38
Ridge Regression
	MSE without CV: 3831.89
	MSE with CV: 3364.53
Bayesian Ridge Regression
	MSE without CV: 3831.89
	MSE with CV: 2998.91
K-Nearest Neighbors
	MSE without CV: 4348.41
	MSE with CV: 3764.74

Run 2:

Linear Regression
	MSE without CV: 2869.01
	MSE with CV: 3000.38
Ridge Regression
	MSE without CV: 3689.43
	MSE with CV: 3364.53
Bayesian Ridge Regression
	MSE without CV: 3689.43
	MSE with CV: 2998.91
K-Nearest Neighbors
	MSE without CV: 3287.32
	MSE with CV: 3764.74

There are a few results to discuss with these results. The first thing to note is that all of the models with cross validation perform better than the normal single data split during run 1, but peform differently in run 2. This is expected as if you only split the data once, then the particualr split could be more predictive of the testing data, but peform worse when exposed to other data. So we can see that sometimes the single split perorms better on the particalr test data, as seen in linear regression of run 2. But the cross validated data is a better predicitor and is consistent across and subsequent testing. 

The next thing to note is that the Bayesian Ridge Regression performs the best out of the three regression models, which all outperfom the K-Nearest Neighbors model. This is expected given the shape of the dataset. Plotting the Diabetes data set it is clear there is a linear relationship. 